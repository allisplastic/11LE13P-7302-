{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading\n",
    "data_dir = 'data/GTSRB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing dataset to 32x32, meansubstraction (Normalize???)\n",
    "\n",
    "data_transforms = {\n",
    "    'Training': transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [1, 1, 1])\n",
    "    ]),\n",
    "    'Test': transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [1, 1, 1])\n",
    "    ]),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    def __init__(self, w, h):\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "    def __call__(self, image):\n",
    "        return transform.resize(\n",
    "        image,\n",
    "        output_shape = (self.w, self.h),\n",
    "        preserve_range = True,\n",
    "        mode = \"constant\"\n",
    "        )\n",
    "    \n",
    "class SubtractMean(object):\n",
    "    def __call__(self, image):\n",
    "        ch1 = image[:, :, 0]\n",
    "        ch2 = image[:, :, 1]\n",
    "        ch3 = image[:, :, 2]\n",
    "        \n",
    "        ch1_substracted = ch1 - np.mean(ch1)\n",
    "        ch2_substracted = ch2 - np.mean(ch2)\n",
    "        ch3_sunstracted = ch3 - np.mean(ch3)\n",
    "        \n",
    "        return np.stack((ch1_substracted, ch2_substracted, ch3_substracted), axis =0)\n",
    "    \n",
    "class MakeTensor:\n",
    "    def __call__(self, obj):\n",
    "        return torch.from_numpy(obj)\n",
    "\n",
    "shared_transform = transforms.Compose(\n",
    "[Resize(32, 32),\n",
    "SubtractMean(),\n",
    "MakeTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines(file_path, encoding = \"utf-8\"):\n",
    "    with open(file_path, \"rt\", encoding = encoding) as f:\n",
    "        for line in f:\n",
    "            yield line.rstrip(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotation(annotation_path):\n",
    "    data = []\n",
    "    for line in lines(annotation_path):\n",
    "        cells = line.split(\";\")\n",
    "        if cells[0] == \"Filename\":\n",
    "            continue\n",
    "        image_path, klass = os.path.join(os.path.dirname(annotation_path), cells[0]), int(cells[-1])\n",
    "        data.append((image_path, klass))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dirs = [o for o in os.listdir('train') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in class_dirs:\n",
    "    csv_file = \"GT-{}.csv\".format(d)\n",
    "    annotation_path = os.path.join('train', d, csv_file)\n",
    "    data += read_annotation(annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39209"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('train/00023/00000_00000.ppm', 23)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path, klass = data[0]\n",
    "sample = io.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTRSB(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        self.size = 0\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        image_path, klass = self.data[index]\n",
    "        image_sample = io.imread(image_path)\n",
    "        return image_sample, klass\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTRSBTrain(GTRSB):\n",
    "    def __init__(self, path = 'train', transform = None):\n",
    "        self.class_dirs = [fold for fold in os.listdir('train') ]\n",
    "        self.num_classes = len(self.class_dirs)\n",
    "        \n",
    "        self.data = []\n",
    "        \n",
    "        for fold in self.class_dirs:\n",
    "            csv = \"GT-{}.csv\".format(fold)\n",
    "            annotation_path = os.path.join('train', fold, csv)\n",
    "            self.data += read_annotation(annotation_path)\n",
    "            \n",
    "        self.size = len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "newobj = GTRSBTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39209"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newobj.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newobj.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 3) # 32 filters: 3 x 3\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size = 3) # 32 filters: 3 x 3\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 3) # 64 filters: 3 x 3\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size = 3) # 64 filters: 3 x 3\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size = 3) # 64 filters: 3 x 3\n",
    "\n",
    "        self.linear1 = nn.Linear(64 * 4 * 4, 512)\n",
    "        self.linear2 = nn.Linear(512, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv, ReLU, Conv, ReLU, Max-pooling\n",
    "        relu1 = F.relu(self.conv1(x.float()))\n",
    "        relu2 = F.relu(self.conv2(relu1))\n",
    "        mp1 = F.max_pool2d(relu2, kernel_size = 2, stride = 2)\n",
    "\n",
    "        # Conv, ReLU, Conv, ReLU, Max-pooling\n",
    "        relu3 = F.relu(self.conv3(mp1))\n",
    "        relu4 = F.relu(self.conv4(relu3))\n",
    "        relu5 = F.relu(self.conv5(relu4))\n",
    "        mp2 = F.max_pool2d(relu5, kernel_size = 2, stride = 2)\n",
    "\n",
    "        # Fully-connected layer\n",
    "        flat = mp2.view(mp2.size(0), -1)\n",
    "        hidden = F.relu(self.linear1(flat))\n",
    "        dropout = F.dropout(hidden)\n",
    "        y = F.log_softmax(self.linear2(dropout), dim = 1)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting train into valid (20%) and train(80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "sgd_momentum = 0.5\n",
    "epochs = 20\n",
    "trainset = GTRSBTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  39209\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples: ', len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_loader(data,\n",
    "                           batch_size = 4,\n",
    "                           valid_size=0.2,\n",
    "                           show_sample=False,\n",
    "                           num_workers=4,\n",
    "                           pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning train and valid\n",
    "    multi-process iterators over the CIFAR-10 dataset. A sample\n",
    "    9x9 grid of the images can be optionally displayed.\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - augment: whether to apply the data augmentation scheme\n",
    "      mentioned in the paper. Only applied on the train split.\n",
    "    - random_seed: fix seed for reproducibility.\n",
    "    - valid_size: percentage split of the training set used for\n",
    "      the validation set. Should be a float in the range [0, 1].\n",
    "    - shuffle: whether to shuffle the train/validation indices.\n",
    "    - show_sample: plot 9x9 sample grid of the dataset.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - train_loader: training set iterator.\n",
    "    - valid_loader: validation set iterator.\n",
    "    \"\"\"\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "\n",
    "    num_train = len(data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "    valid_loader = DataLoader(data, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = get_train_valid_loader(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7842"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39209"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
